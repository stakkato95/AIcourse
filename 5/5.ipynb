{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c62d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da7462",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4dab93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f7d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "print(y_test[1])\n",
    "print(y_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85701e4",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3fa2e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                39250     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50)               200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 50)               200       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,710\n",
      "Trainable params: 42,510\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bbaaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "?BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5ecec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',#tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.5),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45a4559",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "938/938 [==============================] - 3s 2ms/step - loss: 0.5048 - accuracy: 0.8239 - val_loss: 0.4431 - val_accuracy: 0.8443\n",
      "Epoch 2/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8629 - val_loss: 0.3770 - val_accuracy: 0.8653\n",
      "Epoch 3/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8738 - val_loss: 0.3673 - val_accuracy: 0.8639\n",
      "Epoch 4/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8801 - val_loss: 0.3624 - val_accuracy: 0.8716\n",
      "Epoch 5/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3113 - accuracy: 0.8866 - val_loss: 0.3601 - val_accuracy: 0.8700\n",
      "Epoch 6/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3014 - accuracy: 0.8902 - val_loss: 0.3546 - val_accuracy: 0.8690\n",
      "Epoch 7/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2893 - accuracy: 0.8939 - val_loss: 0.3439 - val_accuracy: 0.8762\n",
      "Epoch 8/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2828 - accuracy: 0.8965 - val_loss: 0.3577 - val_accuracy: 0.8725\n",
      "Epoch 9/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2725 - accuracy: 0.8993 - val_loss: 0.3429 - val_accuracy: 0.8794\n",
      "Epoch 10/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2655 - accuracy: 0.9014 - val_loss: 0.3520 - val_accuracy: 0.8804\n",
      "Epoch 11/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2597 - accuracy: 0.9034 - val_loss: 0.3490 - val_accuracy: 0.8769\n",
      "Epoch 12/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2540 - accuracy: 0.9060 - val_loss: 0.3409 - val_accuracy: 0.8804\n",
      "Epoch 13/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.9074 - val_loss: 0.3420 - val_accuracy: 0.8797\n",
      "Epoch 14/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2435 - accuracy: 0.9103 - val_loss: 0.3319 - val_accuracy: 0.8841\n",
      "Epoch 15/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9118 - val_loss: 0.3468 - val_accuracy: 0.8825\n",
      "Epoch 16/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2356 - accuracy: 0.9122 - val_loss: 0.3477 - val_accuracy: 0.8807\n",
      "Epoch 17/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2304 - accuracy: 0.9137 - val_loss: 0.3454 - val_accuracy: 0.8830\n",
      "Epoch 18/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2271 - accuracy: 0.9152 - val_loss: 0.3452 - val_accuracy: 0.8828\n",
      "Epoch 19/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2220 - accuracy: 0.9174 - val_loss: 0.3518 - val_accuracy: 0.8785\n",
      "Epoch 20/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2181 - accuracy: 0.9182 - val_loss: 0.3454 - val_accuracy: 0.8819\n",
      "Epoch 21/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2171 - accuracy: 0.9187 - val_loss: 0.3469 - val_accuracy: 0.8830\n",
      "Epoch 22/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9205 - val_loss: 0.3559 - val_accuracy: 0.8777\n",
      "Epoch 23/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2078 - accuracy: 0.9230 - val_loss: 0.3602 - val_accuracy: 0.8783\n",
      "Epoch 24/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2096 - accuracy: 0.9210 - val_loss: 0.3652 - val_accuracy: 0.8781\n",
      "Epoch 25/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2039 - accuracy: 0.9235 - val_loss: 0.3656 - val_accuracy: 0.8786\n",
      "Epoch 26/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2043 - accuracy: 0.9229 - val_loss: 0.3557 - val_accuracy: 0.8840\n",
      "Epoch 27/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1996 - accuracy: 0.9249 - val_loss: 0.3726 - val_accuracy: 0.8808\n",
      "Epoch 28/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1999 - accuracy: 0.9253 - val_loss: 0.3488 - val_accuracy: 0.8843\n",
      "Epoch 29/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1963 - accuracy: 0.9271 - val_loss: 0.3529 - val_accuracy: 0.8818\n",
      "Epoch 30/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1949 - accuracy: 0.9259 - val_loss: 0.3663 - val_accuracy: 0.8819\n",
      "Epoch 31/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1907 - accuracy: 0.9283 - val_loss: 0.3603 - val_accuracy: 0.8847\n",
      "Epoch 32/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1896 - accuracy: 0.9282 - val_loss: 0.3649 - val_accuracy: 0.8815\n",
      "Epoch 33/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1882 - accuracy: 0.9293 - val_loss: 0.3710 - val_accuracy: 0.8820\n",
      "Epoch 34/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1867 - accuracy: 0.9300 - val_loss: 0.3671 - val_accuracy: 0.8818\n",
      "Epoch 35/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1826 - accuracy: 0.9318 - val_loss: 0.3806 - val_accuracy: 0.8769\n",
      "Epoch 36/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1842 - accuracy: 0.9312 - val_loss: 0.3681 - val_accuracy: 0.8817\n",
      "Epoch 37/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1796 - accuracy: 0.9321 - val_loss: 0.3785 - val_accuracy: 0.8793\n",
      "Epoch 38/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1771 - accuracy: 0.9333 - val_loss: 0.3843 - val_accuracy: 0.8809\n",
      "Epoch 39/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1777 - accuracy: 0.9328 - val_loss: 0.3686 - val_accuracy: 0.8806\n",
      "Epoch 40/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1756 - accuracy: 0.9341 - val_loss: 0.3767 - val_accuracy: 0.8817\n",
      "Epoch 41/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1724 - accuracy: 0.9350 - val_loss: 0.3736 - val_accuracy: 0.8830\n",
      "Epoch 42/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1727 - accuracy: 0.9349 - val_loss: 0.3787 - val_accuracy: 0.8824\n",
      "Epoch 43/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1706 - accuracy: 0.9358 - val_loss: 0.3907 - val_accuracy: 0.8762\n",
      "Epoch 44/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1673 - accuracy: 0.9370 - val_loss: 0.3841 - val_accuracy: 0.8797\n",
      "Epoch 45/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1660 - accuracy: 0.9374 - val_loss: 0.3805 - val_accuracy: 0.8821\n",
      "Epoch 46/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1661 - accuracy: 0.9369 - val_loss: 0.3888 - val_accuracy: 0.8775\n",
      "Epoch 47/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1646 - accuracy: 0.9380 - val_loss: 0.3994 - val_accuracy: 0.8761\n",
      "Epoch 48/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1641 - accuracy: 0.9389 - val_loss: 0.3980 - val_accuracy: 0.8781\n",
      "Epoch 49/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1636 - accuracy: 0.9379 - val_loss: 0.3969 - val_accuracy: 0.8781\n",
      "Epoch 50/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1639 - accuracy: 0.9377 - val_loss: 0.4193 - val_accuracy: 0.8719\n",
      "Epoch 51/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1600 - accuracy: 0.9387 - val_loss: 0.3935 - val_accuracy: 0.8804\n",
      "Epoch 52/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1605 - accuracy: 0.9397 - val_loss: 0.3882 - val_accuracy: 0.8831\n",
      "Epoch 53/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1595 - accuracy: 0.9392 - val_loss: 0.4127 - val_accuracy: 0.8746\n",
      "Epoch 54/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1564 - accuracy: 0.9416 - val_loss: 0.4074 - val_accuracy: 0.8806\n",
      "Epoch 55/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1556 - accuracy: 0.9413 - val_loss: 0.4081 - val_accuracy: 0.8781\n",
      "Epoch 56/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1528 - accuracy: 0.9428 - val_loss: 0.4156 - val_accuracy: 0.8805\n",
      "Epoch 57/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1542 - accuracy: 0.9416 - val_loss: 0.4210 - val_accuracy: 0.8790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1523 - accuracy: 0.9423 - val_loss: 0.4206 - val_accuracy: 0.8724\n",
      "Epoch 59/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1517 - accuracy: 0.9425 - val_loss: 0.4131 - val_accuracy: 0.8787\n",
      "Epoch 60/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1490 - accuracy: 0.9436 - val_loss: 0.4074 - val_accuracy: 0.8817\n",
      "Epoch 61/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9438 - val_loss: 0.4257 - val_accuracy: 0.8760\n",
      "Epoch 62/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1480 - accuracy: 0.9443 - val_loss: 0.4371 - val_accuracy: 0.8773\n",
      "Epoch 63/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1485 - accuracy: 0.9453 - val_loss: 0.4278 - val_accuracy: 0.8780\n",
      "Epoch 64/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1487 - accuracy: 0.9444 - val_loss: 0.4043 - val_accuracy: 0.8812\n",
      "Epoch 65/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1456 - accuracy: 0.9450 - val_loss: 0.4257 - val_accuracy: 0.8835\n",
      "Epoch 66/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1431 - accuracy: 0.9459 - val_loss: 0.4398 - val_accuracy: 0.8752\n",
      "Epoch 67/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1456 - accuracy: 0.9456 - val_loss: 0.4428 - val_accuracy: 0.8729\n",
      "Epoch 68/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1430 - accuracy: 0.9457 - val_loss: 0.4231 - val_accuracy: 0.8802\n",
      "Epoch 69/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1398 - accuracy: 0.9477 - val_loss: 0.4548 - val_accuracy: 0.8750\n",
      "Epoch 70/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1428 - accuracy: 0.9458 - val_loss: 0.4405 - val_accuracy: 0.8781\n",
      "Epoch 71/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1391 - accuracy: 0.9476 - val_loss: 0.4448 - val_accuracy: 0.8781\n",
      "Epoch 72/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1404 - accuracy: 0.9459 - val_loss: 0.4398 - val_accuracy: 0.8779\n",
      "Epoch 73/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1383 - accuracy: 0.9474 - val_loss: 0.4486 - val_accuracy: 0.8733\n",
      "Epoch 74/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1374 - accuracy: 0.9477 - val_loss: 0.4577 - val_accuracy: 0.8752\n",
      "Epoch 75/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1391 - accuracy: 0.9477 - val_loss: 0.4564 - val_accuracy: 0.8749\n",
      "Epoch 76/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1367 - accuracy: 0.9485 - val_loss: 0.4414 - val_accuracy: 0.8781\n",
      "Epoch 77/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1350 - accuracy: 0.9503 - val_loss: 0.4361 - val_accuracy: 0.8812\n",
      "Epoch 78/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1384 - accuracy: 0.9479 - val_loss: 0.4392 - val_accuracy: 0.8784\n",
      "Epoch 79/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1336 - accuracy: 0.9499 - val_loss: 0.4603 - val_accuracy: 0.8735\n",
      "Epoch 80/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1327 - accuracy: 0.9499 - val_loss: 0.4441 - val_accuracy: 0.8807\n",
      "Epoch 81/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1349 - accuracy: 0.9483 - val_loss: 0.4482 - val_accuracy: 0.8797\n",
      "Epoch 82/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1319 - accuracy: 0.9503 - val_loss: 0.4712 - val_accuracy: 0.8735\n",
      "Epoch 83/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.4482 - val_accuracy: 0.8787\n",
      "Epoch 84/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1314 - accuracy: 0.9506 - val_loss: 0.4614 - val_accuracy: 0.8791\n",
      "Epoch 85/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1328 - accuracy: 0.9500 - val_loss: 0.4550 - val_accuracy: 0.8760\n",
      "Epoch 86/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1281 - accuracy: 0.9514 - val_loss: 0.4769 - val_accuracy: 0.8760\n",
      "Epoch 87/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1277 - accuracy: 0.9517 - val_loss: 0.4585 - val_accuracy: 0.8782\n",
      "Epoch 88/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1262 - accuracy: 0.9523 - val_loss: 0.4684 - val_accuracy: 0.8756\n",
      "Epoch 89/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1288 - accuracy: 0.9513 - val_loss: 0.4603 - val_accuracy: 0.8759\n",
      "Epoch 90/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1255 - accuracy: 0.9528 - val_loss: 0.4639 - val_accuracy: 0.8781\n",
      "Epoch 91/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1261 - accuracy: 0.9531 - val_loss: 0.4594 - val_accuracy: 0.8821\n",
      "Epoch 92/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1260 - accuracy: 0.9520 - val_loss: 0.4611 - val_accuracy: 0.8780\n",
      "Epoch 93/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1237 - accuracy: 0.9538 - val_loss: 0.4688 - val_accuracy: 0.8788\n",
      "Epoch 94/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1225 - accuracy: 0.9540 - val_loss: 0.4718 - val_accuracy: 0.8811\n",
      "Epoch 95/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1234 - accuracy: 0.9536 - val_loss: 0.4790 - val_accuracy: 0.8736\n",
      "Epoch 96/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1212 - accuracy: 0.9545 - val_loss: 0.4869 - val_accuracy: 0.8769\n",
      "Epoch 97/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1213 - accuracy: 0.9540 - val_loss: 0.4975 - val_accuracy: 0.8754\n",
      "Epoch 98/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1207 - accuracy: 0.9540 - val_loss: 0.4811 - val_accuracy: 0.8771\n",
      "Epoch 99/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.9540 - val_loss: 0.4924 - val_accuracy: 0.8773\n",
      "Epoch 100/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1203 - accuracy: 0.9548 - val_loss: 0.4865 - val_accuracy: 0.8747\n",
      "Epoch 101/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1201 - accuracy: 0.9550 - val_loss: 0.4962 - val_accuracy: 0.8792\n",
      "Epoch 102/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1183 - accuracy: 0.9557 - val_loss: 0.4836 - val_accuracy: 0.8777\n",
      "Epoch 103/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1159 - accuracy: 0.9555 - val_loss: 0.4889 - val_accuracy: 0.8750\n",
      "Epoch 104/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1152 - accuracy: 0.9564 - val_loss: 0.4969 - val_accuracy: 0.8772\n",
      "Epoch 105/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1189 - accuracy: 0.9543 - val_loss: 0.5018 - val_accuracy: 0.8775\n",
      "Epoch 106/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1174 - accuracy: 0.9560 - val_loss: 0.4862 - val_accuracy: 0.8779\n",
      "Epoch 107/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1158 - accuracy: 0.9562 - val_loss: 0.5113 - val_accuracy: 0.8713\n",
      "Epoch 108/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1181 - accuracy: 0.9557 - val_loss: 0.4939 - val_accuracy: 0.8730\n",
      "Epoch 109/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1168 - accuracy: 0.9559 - val_loss: 0.5083 - val_accuracy: 0.8774\n",
      "Epoch 110/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1173 - accuracy: 0.9567 - val_loss: 0.5085 - val_accuracy: 0.8772\n",
      "Epoch 111/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.4920 - val_accuracy: 0.8761\n",
      "Epoch 112/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1153 - accuracy: 0.9568 - val_loss: 0.5000 - val_accuracy: 0.8757\n",
      "Epoch 113/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1141 - accuracy: 0.9564 - val_loss: 0.5161 - val_accuracy: 0.8730\n",
      "Epoch 114/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1138 - accuracy: 0.9566 - val_loss: 0.5091 - val_accuracy: 0.8759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1121 - accuracy: 0.9585 - val_loss: 0.5186 - val_accuracy: 0.8747\n",
      "Epoch 116/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1160 - accuracy: 0.9564 - val_loss: 0.5182 - val_accuracy: 0.8751\n",
      "Epoch 117/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1136 - accuracy: 0.9568 - val_loss: 0.5115 - val_accuracy: 0.8743\n",
      "Epoch 118/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1104 - accuracy: 0.9583 - val_loss: 0.5050 - val_accuracy: 0.8742\n",
      "Epoch 119/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1101 - accuracy: 0.9584 - val_loss: 0.5337 - val_accuracy: 0.8674\n",
      "Epoch 120/120\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1116 - accuracy: 0.9578 - val_loss: 0.5063 - val_accuracy: 0.8720\n",
      "CPU times: user 7min 41s, sys: 1min 32s, total: 9min 14s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3cc897ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.340\n",
      "test accuracy 0.882\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'test loss {score[0]:.3f}')\n",
    "print(f'test accuracy {score[1]:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MLLearning)",
   "language": "python",
   "name": "mllearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
